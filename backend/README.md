# ğŸŒ€ Project Pulse â€“ AI-Powered Sprint Analyzer

Project Pulse is a local AI-powered tool designed to help agile teams get meaningful, actionable insights from GitHub sprints.  
It fetches GitHub activity data (commits, issues, pull requests) and generates smart sprint summaries using **open-source LLMs** running **entirely offline**.

---

## ğŸš€ Phases Overview

| Phase | Name                          | Description                                               |
|-------|-------------------------------|-----------------------------------------------------------|
| 1ï¸âƒ£    | GitHub Sprint Data Fetcher     | Collects commits, issues, and PRs via GitHub API          |
| 2ï¸âƒ£    | AI Sprint Summary Generator   | Generates human-readable sprint summaries using Ollama    |
| 3ï¸âƒ£    | [Upcoming] Frontend Dashboard | UI for repo selection, summary visualization & metrics    |

---

## ğŸ›  Tech Stack

| Layer     | Tool/Tech                  |
|-----------|----------------------------|
| Backend   | Python 3.8+, FastAPI       |
| GitHub API| REST API v3 + PAT Auth     |
| LLM Model | Mistral (via [Ollama](https://ollama.com)) |
| Local AI  | Ollama (lightweight runtime) |
| Frontend  | [Planned] React + Tailwind |

---

## ğŸ“ Project Structure
    project-pulse/
    â”œâ”€â”€ backend/
    â”‚ â”œâ”€â”€ main.py # FastAPI app and route definitions
    â”‚ â”œâ”€â”€ github_fetcher.py # GitHub sprint data collector
    â”‚ â”œâ”€â”€ sprint_summarizer.py # LLM-based summary generation
    â”‚ â”œâ”€â”€ test_data.json # Sample sprint input for testing
    â”‚ â”œâ”€â”€ .env # GitHub Personal Access Token
    â”‚ â”œâ”€â”€ requirements.txt # Python dependencies
    â”‚ â””â”€â”€ README.md # You're reading this!


---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repo

    ```bash
    git clone https://github.com/prakashwaddar628/project-pulse.git
    cd project-pulse/backend

    - 2ï¸âƒ£ Create Virtual Environment & Activate

        python -m venv venv
        venv\Scripts\activate   # Windows
    - 3ï¸âƒ£ Install Dependencies

        pip install -r requirements.txt
    - 4ï¸âƒ£ Add GitHub Token in .env
        Create a .env file:

        - GITHUB_TOKEN=ghp_your_token_here
            - ğŸ” Generate from GitHub â†’ Settings â†’ Developer Settings â†’ Personal Access Tokens â†’ Repo scope

    - 5ï¸âƒ£ Install & Start Ollama (for AI)
        - Download Ollama: https://ollama.com/download

        - Run the Mistral model (offline):
            - ollama run mistral
    - 6ï¸âƒ£ Run the Backend Server
        - uvicorn main:app --reload
        - API Docs:
            - Swagger UI â†’ http://127.0.0.1:8000/docs

    - ğŸ“¦ Phase 1 â€“ GitHub Sprint Data Fetcher
        - Fetch all relevant sprint data from a GitHub repo within a specific time window.

        - Example Request

GET /fetch_sprint/
    - ?owner=vercel
    - &repo=next.js
    - &start_date=2024-06-01T00:00:00Z
    - &end_date=2024-06-10T00:00:00Z
    - Returns

    {
      "commits": [...],
      "issues": [...],
      "pull_requests": [...]
    }

- Phase 2 â€“ AI Sprint Summary (Local Mistral via Ollama)
    This module takes in sprint data and generates a professional summary.

    - ğŸ”„ Test API Endpoint
     - GET /test_summary/
        - ğŸ“„ Uses sample test_data.json and returns:

    {
        "summary": "The team completed multiple UI updates, optimized dashboard performance, and resolved issue #42 during this sprint..."
    }
    No OpenAI key. No cloud API. Just Mistral running locally via Ollama ğŸš€

ğŸ§© Coming Soon: Phase 3 â€“ React UI
Select GitHub repo & date range

Visualize commit/issue/PR trends

View/download AI summaries

Export to PDF or share to Slack

ğŸ™Œ Contributing
Pull requests are welcome!
If youâ€™d like to improve prompts, add charts, or support other models (LLaMA3, CodeLLaMA), feel free to fork and contribute.

ğŸ“œ License
MIT Â© Prakash